{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6GuKTjzPaZr",
        "outputId": "8c8434cb-b0eb-413d-e45c-fbff0d688a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.7.0\n",
            "Uninstalling tensorflow-2.7.0:\n",
            "  Successfully uninstalled tensorflow-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall tensorflow --yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYQc6VkgPd6h",
        "outputId": "6547a31f-9eca-4b78-e3c7-ba64732a4842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.2.0\n",
            "  Downloading tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2 MB 4.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.17.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
            "\u001b[K     |████████████████████████████████| 454 kB 45.6 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.3.0,>=2.2.0\n",
            "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 43.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.12.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.13.3)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 38.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.43.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.6)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.1)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, h5py, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztcrlpYQPzzO",
        "outputId": "152ce37a-f9f1-43b4-ee84-7eed1e0602e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plot-metric\n",
            "  Downloading plot_metric-0.0.6-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.7/dist-packages (from plot-metric) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plot-metric) (1.4.1)\n",
            "Requirement already satisfied: colorlover>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from plot-metric) (0.3.0)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from plot-metric) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from plot-metric) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from plot-metric) (1.19.5)\n",
            "Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plot-metric) (0.11.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot-metric) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot-metric) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot-metric) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->plot-metric) (3.0.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->plot-metric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.2->plot-metric) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->plot-metric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->plot-metric) (1.1.0)\n",
            "Installing collected packages: plot-metric\n",
            "Successfully installed plot-metric-0.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install plot-metric "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas  as pd\n",
        "import numpy   as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from zipfile import ZipFile\n",
        "from shutil import copyfile, copyfileobj\n",
        "import gzip\n",
        "from IPython.display import clear_output\n",
        "import cv2\n",
        "import os\n",
        "from pylab import rcParams\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import scipy\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans, MeanShift\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGowHiNpvhjT",
        "outputId": "bdc1b71b-e0de-478d-bdde-fe9b24a432ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version:  2.2.0\n",
            "Eager mode:  True\n",
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import math\n",
        "import seaborn as sns; sns.set()\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "from tensorflow.keras.layers import Lambda, RepeatVector, Reshape, Input\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import MaxPooling2D, GlobalMaxPool2D\n",
        "from tensorflow.keras.layers import concatenate, add\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras import backend as K\n",
        "import joblib\n",
        "import gc"
      ],
      "metadata": {
        "id": "FSPjHvVwzIDX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7bw8d0FxP58X"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"sanjanav98\"\n",
        "os.environ['KAGGLE_KEY'] = \"2bb32d3324e753a524b072e9775b3e7a\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d andrewmvd/covid19-ct-scans"
      ],
      "metadata": {
        "id": "P8QFyuLwc-1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile('covid19-ct-scans.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall('covid19-ct-scans')"
      ],
      "metadata": {
        "id": "TQhEff4kdB-m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = pd.read_csv('/content/covid19-ct-scans/metadata.csv')\n",
        "raw_data = raw_data.replace('../input/covid19-ct-scans/','/content/covid19-ct-scans/',regex=True)\n",
        "raw_data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "tZa4NHc2dD0R",
        "outputId": "f02b80ae-f24f-4a8d-adac-1aa96658728f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-617bc29a-2f39-49c5-9806-958cb1bdabfa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ct_scan</th>\n",
              "      <th>lung_mask</th>\n",
              "      <th>infection_mask</th>\n",
              "      <th>lung_and_infection_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/covid19-ct-scans/ct_scans/coronacases...</td>\n",
              "      <td>/content/covid19-ct-scans/lung_mask/coronacase...</td>\n",
              "      <td>/content/covid19-ct-scans/infection_mask/coron...</td>\n",
              "      <td>/content/covid19-ct-scans/lung_and_infection_m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/covid19-ct-scans/ct_scans/coronacases...</td>\n",
              "      <td>/content/covid19-ct-scans/lung_mask/coronacase...</td>\n",
              "      <td>/content/covid19-ct-scans/infection_mask/coron...</td>\n",
              "      <td>/content/covid19-ct-scans/lung_and_infection_m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/covid19-ct-scans/ct_scans/coronacases...</td>\n",
              "      <td>/content/covid19-ct-scans/lung_mask/coronacase...</td>\n",
              "      <td>/content/covid19-ct-scans/infection_mask/coron...</td>\n",
              "      <td>/content/covid19-ct-scans/lung_and_infection_m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/covid19-ct-scans/ct_scans/coronacases...</td>\n",
              "      <td>/content/covid19-ct-scans/lung_mask/coronacase...</td>\n",
              "      <td>/content/covid19-ct-scans/infection_mask/coron...</td>\n",
              "      <td>/content/covid19-ct-scans/lung_and_infection_m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/covid19-ct-scans/ct_scans/coronacases...</td>\n",
              "      <td>/content/covid19-ct-scans/lung_mask/coronacase...</td>\n",
              "      <td>/content/covid19-ct-scans/infection_mask/coron...</td>\n",
              "      <td>/content/covid19-ct-scans/lung_and_infection_m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-617bc29a-2f39-49c5-9806-958cb1bdabfa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-617bc29a-2f39-49c5-9806-958cb1bdabfa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-617bc29a-2f39-49c5-9806-958cb1bdabfa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             ct_scan  ...                            lung_and_infection_mask\n",
              "0  /content/covid19-ct-scans/ct_scans/coronacases...  ...  /content/covid19-ct-scans/lung_and_infection_m...\n",
              "1  /content/covid19-ct-scans/ct_scans/coronacases...  ...  /content/covid19-ct-scans/lung_and_infection_m...\n",
              "2  /content/covid19-ct-scans/ct_scans/coronacases...  ...  /content/covid19-ct-scans/lung_and_infection_m...\n",
              "3  /content/covid19-ct-scans/ct_scans/coronacases...  ...  /content/covid19-ct-scans/lung_and_infection_m...\n",
              "4  /content/covid19-ct-scans/ct_scans/coronacases...  ...  /content/covid19-ct-scans/lung_and_infection_m...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 512"
      ],
      "metadata": {
        "id": "BG9j12lCdFT2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clahe_enhancer(test_img, demo):\n",
        "\n",
        "  test_img = test_img*255\n",
        "  test_img = np.uint8(test_img)\n",
        "  test_img_flattened = test_img.flatten()\n",
        "  \n",
        "  clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "  clahe_image = clahe.apply(test_img)\n",
        "  clahe_image_flattened = clahe_image.flatten()\n",
        "\n",
        "  if demo == 1:\n",
        "\n",
        "    fig = plt.figure()\n",
        "    rcParams['figure.figsize'] = 10,10\n",
        "    \n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.imshow(test_img, cmap='bone')\n",
        "    plt.title(\"Original CT-Scan\")\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.hist(test_img_flattened)\n",
        "    plt.title(\"Histogram of Original CT-Scan\")\n",
        "\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.imshow(clahe_image, cmap='bone')\n",
        "    plt.title(\"CLAHE Enhanced CT-Scan\")\n",
        "\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.hist(clahe_image_flattened)\n",
        "    plt.title(\"Histogram of CLAHE Enhanced CT-Scan\")\n",
        "\n",
        "  return(clahe_image)"
      ],
      "metadata": {
        "id": "uZnXUE2RdHeG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cropper(test_img, demo):\n",
        "\n",
        "  test_img = test_img*255\n",
        "  test_img = np.uint8(test_img)\n",
        "\n",
        "  # ret, thresh = cv2.threshold(test_img, 50, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) \n",
        "  # ret, thresh = cv2.threshold(test_img, ret, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) \n",
        "\n",
        "  contours,hierarchy = cv2.findContours(test_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  areas = [cv2.contourArea(c) for c in contours]\n",
        "\n",
        "  x = np.argsort(areas)\n",
        "\n",
        "  max_index = x[x.size - 1]\n",
        "  cnt1=contours[max_index]\n",
        "  second_max_index = x[x.size - 2]\n",
        "  cnt2 = contours[second_max_index]\n",
        "\n",
        "  # max_index = np.argmax(areas)\n",
        "  # cnt=contours[max_index]\n",
        "\n",
        "  x,y,w,h = cv2.boundingRect(cnt1)\n",
        "  p,q,r,s = cv2.boundingRect(cnt2)\n",
        "\n",
        "  cropped1 = test_img[y:y+h, x:x+w]\n",
        "  cropped1 = cv2.resize(cropped1, dsize=(125,250), interpolation=cv2.INTER_AREA)\n",
        "  cropped2 = test_img[q:q+s, p:p+r]\n",
        "  cropped2 = cv2.resize(cropped2, dsize=(125,250), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "  fused = np.concatenate((cropped1, cropped2), axis=1)\n",
        "\n",
        "  # super_cropped = test_img[y+7:y+h-20, x+25:x+w-25]\n",
        "  points_lung1 = []\n",
        "  points_lung2 = []\n",
        "\n",
        "  points_lung1.append(x); points_lung1.append(y); points_lung1.append(w); points_lung1.append(h)\n",
        "  points_lung2.append(p); points_lung2.append(q); points_lung2.append(r); points_lung2.append(s)\n",
        "  \n",
        "  if demo == 1:\n",
        "\n",
        "    fig = plt.figure()\n",
        "    rcParams['figure.figsize'] = 35, 35\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(test_img, cmap='bone')\n",
        "    plt.title(\"Original CT-Scan\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(thresh, cmap='bone')\n",
        "    plt.title(\"Binary Mask\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(fused, cmap='bone')\n",
        "    plt.title(\"Cropped CT scan after making bounding rectangle\")\n",
        "\n",
        "    # plt.subplot(1, 4, 4)\n",
        "    # plt.imshow(super_cropped, cmap='bone')\n",
        "    # plt.title(\"Cropped further manually\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  return(fused, points_lung1, points_lung2)"
      ],
      "metadata": {
        "id": "bNBW3bcMdJTq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_nii_demo(filepath, data):\n",
        "    '''\n",
        "    Reads .nii file and returns pixel array\n",
        "    '''\n",
        "    ct_scan = nib.load(filepath)\n",
        "    array   = ct_scan.get_fdata()\n",
        "    array   = np.rot90(np.array(array))\n",
        "    slices = array.shape[2]\n",
        "    array = array[:,:,round(slices*0.2):round(slices*0.8)]\n",
        "    array = np.reshape(np.rollaxis(array, 2),(array.shape[2],array.shape[0],array.shape[1], 1))\n",
        "\n",
        "    for img_no in range(0, array.shape[0]):\n",
        "        # array = Image.resize(array[...,img_no], (img_size,img_size))\n",
        "        img = cv2.resize(array[img_no], dsize=(img_size, img_size), interpolation=cv2.INTER_AREA)\n",
        "        xmax, xmin = img.max(), img.min()\n",
        "        img = (img - xmin)/(xmax - xmin)\n",
        "        data.append(img)"
      ],
      "metadata": {
        "id": "9pD0gkVZdgwR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_points1 = []\n",
        "all_points2 = []"
      ],
      "metadata": {
        "id": "RtiTtGtwdi-m"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_nii(filepath, data, string):\n",
        "    '''\n",
        "    Reads .nii file and returns pixel array\n",
        "\n",
        "    '''\n",
        "    global all_points1\n",
        "    global all_points2\n",
        "    ct_scan = nib.load(filepath)\n",
        "    array   = ct_scan.get_fdata()\n",
        "    array   = np.rot90(np.array(array))\n",
        "    slices = array.shape[2]\n",
        "    array = array[:,:,round(slices*0.2):round(slices*0.8)]\n",
        "    array = np.reshape(np.rollaxis(array, 2),(array.shape[2],array.shape[0],array.shape[1],1))\n",
        "    #print(array.shape[2])\n",
        "    #array = skimage.transform.resize(array, (array.shape[2], img_size, img_size))\n",
        "    #array = cv2.resize(array, dsize=(img_size, img_size), interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "\n",
        "    if string == \"lungs\":\n",
        "      all_points1 = []\n",
        "      all_points2 = []\n",
        "\n",
        "    for img_no in range(0, array.shape[0]):\n",
        "        if string == 'lungs' and np.unique(array[img_no]).size == 1:\n",
        "          continue\n",
        "        img = cv2.resize(array[img_no], dsize=(img_size, img_size), interpolation=cv2.INTER_AREA)\n",
        "        xmax, xmin = img.max(), img.min()\n",
        "        img = (img - xmin)/(xmax - xmin)\n",
        "\n",
        "        if string == 'lungs':\n",
        "          # img = np.uint8(img*255) \n",
        "          img[img>0]=1\n",
        "          img, points1, points2 = cropper(img, demo = 0)\n",
        "          all_points1.append((points1[0], points1[1], points1[2], points1[3]))\n",
        "          all_points2.append((points2[0], points2[1], points2[2], points2[3]))\n",
        "          continue \n",
        "\n",
        "        if string == \"cts\" and img_no < len(all_points1):\n",
        "          img = clahe_enhancer(img, demo = 0)\n",
        "          # img, points1, points2 = cropper(img, demo = 0)\n",
        "          # all_points1.append((points1[0], points1[1], points1[2], points1[3]))\n",
        "          # all_points2.append((points2[0], points2[1], points2[2], points2[3]))   \n",
        "          a,b,c,d = all_points1[img_no]\n",
        "          e,f,g,h = all_points2[img_no]\n",
        "          img1 = img[b:b+d, a:a+c]\n",
        "          img1 = cv2.resize(img1, dsize=(125,250), interpolation=cv2.INTER_AREA)\n",
        "          img2 = img[f:f+h, e:e+g]\n",
        "          img2 = cv2.resize(img2, dsize=(125,250), interpolation=cv2.INTER_AREA)\n",
        "          img = np.concatenate((img1, img2), axis=1)    \n",
        "\n",
        "        if string == \"infections\" and img_no < len(all_points1):\n",
        "          a,b,c,d = all_points1[img_no]\n",
        "          e,f,g,h = all_points2[img_no]\n",
        "          img = np.uint8(img*255)\n",
        "          img1 = img[b:b+d, a:a+c]\n",
        "          img1 = cv2.resize(img1, dsize=(125,250), interpolation=cv2.INTER_AREA)\n",
        "          img2 = img[f:f+h, e:e+g]\n",
        "          img2 = cv2.resize(img2, dsize=(125,250), interpolation=cv2.INTER_AREA)\n",
        "          img = np.concatenate((img1, img2), axis=1)\n",
        "\n",
        "\n",
        "        # img = cv2.resize(img, dsize=(192, 192), interpolation=cv2.INTER_LINEAR)\n",
        "        # img = img/255\n",
        "        #  remember to normalize again\n",
        "        # also resize images and masks for all\n",
        "        \n",
        "        data.append(img)"
      ],
      "metadata": {
        "id": "uaaGyIcxdlON"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cts = []\n",
        "infections = []"
      ],
      "metadata": {
        "id": "rLFRHfjPdpOR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    read_nii(raw_data.loc[i,'ct_scan'], cts, 'cts') \n",
        "    read_nii(raw_data.loc[i,'infection_mask'], infections, 'infections')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RziOwmXxdrN5",
        "outputId": "cb1f76fe-29a7-445a-a32b-be3ec082de6e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_label = []\n",
        "for i in range(len(infections)):\n",
        "  if (infections[i] == 1).sum() != 0:\n",
        "    y_label.append(1)\n",
        "  else:\n",
        "    y_label.append(0)"
      ],
      "metadata": {
        "id": "ekRD8GH9VYvd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#new\n",
        "print(y_label.count(0), y_label.count(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSbFBLyEdv__",
        "outputId": "25010a24-8080-4943-d71e-183f443c30a0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "498 1614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_dim = 224"
      ],
      "metadata": {
        "id": "CiwcP01Rdx09"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(cts)):\n",
        "  cts[i] = cv2.resize(cts[i], dsize=(new_dim, new_dim), interpolation=cv2.INTER_LINEAR)"
      ],
      "metadata": {
        "id": "Z3rp1DgFd-Ma"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cts = np.array(cts)"
      ],
      "metadata": {
        "id": "fdEjKTtaLczy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucdJssQfLeQR",
        "outputId": "e951196d-a6d4-4edf-ab82-3789314b4fa3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2112, 224, 224)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cts = cts.reshape(len(cts), new_dim,new_dim,1)\n",
        "y_label = np.array(y_label)\n",
        "print(cts.shape, y_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM3owua6eFpx",
        "outputId": "7e339f19-8ae1-46df-dd35-89aae3addd79"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2112, 224, 224, 1) (2112,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cts = cts/255"
      ],
      "metadata": {
        "id": "NUBgENiUePvc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "for train_index, test_index in sss.split(cts, y_label):\n",
        "  x_train, x_valid = cts[train_index], cts[test_index]\n",
        "  y_train, y_valid = y_label[train_index], y_label[test_index]"
      ],
      "metadata": {
        "id": "soTq6_gaejoN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_label, return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJWwsHWGelae",
        "outputId": "26f56686-ed90-4eac-ac41-de7580d9ecc5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([ 498, 1614]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_train, return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKH5_kSLenbi",
        "outputId": "e881edcd-a0bd-4ae7-e14c-074d6cba3064"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([ 349, 1129]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, x_valid.shape)\n",
        "print(y_train.shape, y_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zPZjWIJepGN",
        "outputId": "5de97cfe-d4e9-4d9f-86a3-0dfe52f2ced3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1478, 224, 224, 1) (634, 224, 224, 1)\n",
            "(1478,) (634,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (new_dim,new_dim,1)"
      ],
      "metadata": {
        "id": "QJAskuQDAU23"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = Sequential()\n",
        "\n",
        "#Convolution\n",
        "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=input_shape))\n",
        "\n",
        "#Pooling\n",
        "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# 2nd Convolution\n",
        "cnn.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
        "\n",
        "# 2nd Pooling layer\n",
        "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Flatten the layer\n",
        "cnn.add(Flatten())\n",
        "\n",
        "# Fully Connected Layers\n",
        "cnn.add(Dense(activation = 'relu', units = 128))\n",
        "cnn.add(Dense(activation = 'sigmoid', units = 1))\n",
        "\n",
        "# Compile the Neural network\n",
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "ZA6POpoQAErG"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', padding=\"same\", kernel_initializer=\"he_normal\", input_shape=(new_dim,new_dim,1)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "# The third convolution\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "# The fourth convolution\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "# # The fifth convolution\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "# Flatten the results to feed into a DNN\n",
        "model.add(Flatten())\n",
        "# 512 neuron hidden layer\n",
        "model.add(Dense(512, activation='relu'))\n",
        "# Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('dandelions') and 1 for the other ('grass')\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7t2gueeECk5",
        "outputId": "221c7774-6c64-41fe-a10a-c0d01340e7d1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 224, 224, 16)      160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 110, 110, 64)      9280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 55, 55, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 53, 53, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               4719104   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 4,802,913\n",
            "Trainable params: 4,802,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "optimizer=tf.keras.optimizers.RMSprop(),\n",
        "metrics='accuracy')"
      ],
      "metadata": {
        "id": "5I-cve1OOcOV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = cnn.fit(x_train, y_train, batch_size=32, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE7kMKf8E7gm",
        "outputId": "88998534-f9c5-4f43-ea1f-40f3e70ed089"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "47/47 [==============================] - 3s 65ms/step - loss: 0.5850 - accuracy: 0.7503\n",
            "Epoch 2/50\n",
            "47/47 [==============================] - 3s 62ms/step - loss: 0.5540 - accuracy: 0.7639\n",
            "Epoch 3/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.5537 - accuracy: 0.7639\n",
            "Epoch 4/50\n",
            "47/47 [==============================] - 3s 62ms/step - loss: 0.5587 - accuracy: 0.7639\n",
            "Epoch 5/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.5451 - accuracy: 0.7639\n",
            "Epoch 6/50\n",
            "47/47 [==============================] - 3s 62ms/step - loss: 0.5337 - accuracy: 0.7639\n",
            "Epoch 7/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.4937 - accuracy: 0.7639\n",
            "Epoch 8/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.4471 - accuracy: 0.7916\n",
            "Epoch 9/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.3868 - accuracy: 0.8281\n",
            "Epoch 10/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.3589 - accuracy: 0.8478\n",
            "Epoch 11/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.3102 - accuracy: 0.8620\n",
            "Epoch 12/50\n",
            "47/47 [==============================] - 3s 62ms/step - loss: 0.2600 - accuracy: 0.8836\n",
            "Epoch 13/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.2281 - accuracy: 0.9039\n",
            "Epoch 14/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.1947 - accuracy: 0.9310\n",
            "Epoch 15/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.2323 - accuracy: 0.9073\n",
            "Epoch 16/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.1937 - accuracy: 0.9263\n",
            "Epoch 17/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.1465 - accuracy: 0.9486\n",
            "Epoch 18/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.1537 - accuracy: 0.9418\n",
            "Epoch 19/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.1763 - accuracy: 0.9330\n",
            "Epoch 20/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.1263 - accuracy: 0.9499\n",
            "Epoch 21/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.1283 - accuracy: 0.9526\n",
            "Epoch 22/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.1146 - accuracy: 0.9553\n",
            "Epoch 23/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.1030 - accuracy: 0.9614\n",
            "Epoch 24/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0938 - accuracy: 0.9628\n",
            "Epoch 25/50\n",
            "47/47 [==============================] - 3s 60ms/step - loss: 0.1032 - accuracy: 0.9635\n",
            "Epoch 26/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0858 - accuracy: 0.9689\n",
            "Epoch 27/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0790 - accuracy: 0.9716\n",
            "Epoch 28/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0946 - accuracy: 0.9648\n",
            "Epoch 29/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.1112 - accuracy: 0.9581\n",
            "Epoch 30/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0813 - accuracy: 0.9702\n",
            "Epoch 31/50\n",
            "47/47 [==============================] - 3s 60ms/step - loss: 0.0744 - accuracy: 0.9709\n",
            "Epoch 32/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0981 - accuracy: 0.9614\n",
            "Epoch 33/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0829 - accuracy: 0.9662\n",
            "Epoch 34/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0862 - accuracy: 0.9641\n",
            "Epoch 35/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0812 - accuracy: 0.9621\n",
            "Epoch 36/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0892 - accuracy: 0.9635\n",
            "Epoch 37/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.1183 - accuracy: 0.9526\n",
            "Epoch 38/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0761 - accuracy: 0.9689\n",
            "Epoch 39/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0641 - accuracy: 0.9770\n",
            "Epoch 40/50\n",
            "47/47 [==============================] - 3s 60ms/step - loss: 0.0606 - accuracy: 0.9723\n",
            "Epoch 41/50\n",
            "47/47 [==============================] - 3s 60ms/step - loss: 0.0649 - accuracy: 0.9763\n",
            "Epoch 42/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0706 - accuracy: 0.9716\n",
            "Epoch 43/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0593 - accuracy: 0.9763\n",
            "Epoch 44/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0590 - accuracy: 0.9736\n",
            "Epoch 45/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0922 - accuracy: 0.9635\n",
            "Epoch 46/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0682 - accuracy: 0.9716\n",
            "Epoch 47/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0564 - accuracy: 0.9770\n",
            "Epoch 48/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0632 - accuracy: 0.9736\n",
            "Epoch 49/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0490 - accuracy: 0.9783\n",
            "Epoch 50/50\n",
            "47/47 [==============================] - 3s 61ms/step - loss: 0.0551 - accuracy: 0.9736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('covid_detection.h5')"
      ],
      "metadata": {
        "id": "JbcUcYfC0ePO"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_valid, y_valid, batch_size=32)"
      ],
      "metadata": {
        "id": "2du38ql2FB3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669bfdab-1fa6-4cc8-e2ee-e63b8c03947c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 31ms/step - loss: 0.0593 - accuracy: 0.9826\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Covid-19 detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}